{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import os\n",
    "import getpass\n",
    "from langsmith_utils import extract_and_save_all_child_runs_by_project\n",
    "from src.settings import get_settings\n",
    "\n",
    "settings = get_settings()\n",
    "BASE_DIR = settings.base_dir\n",
    "EHRXQA_CFG = settings.ehrxqa\n",
    "BASE_NAME = \"xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent\"\n",
    "\n",
    "client = Client()\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith_utils import extract_plan_and_details\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def save_reduced_details(project_name, data_path=None):\n",
    "    data_path = Path(data_path) if data_path else EHRXQA_CFG.output_dir\n",
    "    test_run_folder = data_path / f\"{project_name}-details\"\n",
    "    assert test_run_folder.exists(), f\"{test_run_folder} does not exist\"\n",
    "    test_run_files = list(test_run_folder.glob(\"*.json\"))\n",
    "    reduced_run_folder = data_path / f\"{project_name}-details-reduced\"\n",
    "    reduced_run_folder.mkdir(parents=True, exist_ok=True)\n",
    "    all_plans = []\n",
    "    for test_run_file in tqdm(test_run_files):\n",
    "        try:\n",
    "            i = int(test_run_file.stem)\n",
    "            with test_run_file.open(\"r\") as f:\n",
    "                data = json.load(f)\n",
    "            _result = extract_plan_and_details(data)\n",
    "            reduced_run_path = reduced_run_folder / f\"{i}.json\"\n",
    "            with reduced_run_path.open(\"w\") as f:\n",
    "                json.dump(_result, f, indent=2)\n",
    "            all_plans.append(_result)\n",
    "        except ValueError:\n",
    "            print(f\"Skipping {test_run_file.name}\")\n",
    "            continue\n",
    "    output_path = reduced_run_folder.parent / f\"{project_name}-details-reduced.json\"\n",
    "    with output_path.open(\"w\") as f:\n",
    "        json.dump(all_plans, f, indent=2)\n",
    "    print(f\"Saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"xmode-vqa-gpt_4o-english-13\"\n",
    "project_name=os.environ[\"LANGCHAIN_PROJECT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:00<00:00, 40.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to experiments/xmode/en/xmode-vqa-gpt_4o-english-13-details-reduced.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# extract_and_save_all_child_runs_by_project(project_name)\n",
    "save_reduced_details(project_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 52/52 [00:01<00:00, 42.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to experiments/xmode/en/xmode-vqa-gpt_4o-english-52-details-reduced.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# extract_and_save_all_child_runs_by_project(project_name)\n",
    "save_reduced_details(project_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = EHRXQA_CFG.output_dir\n",
    "json_file_1 = data_path / \"xmode-vqa-gpt_4o-english-13-details-reduced.json\"\n",
    "json_file_2 = data_path / \"xmode-vqa-gpt_4o-english-52-details-reduced.json\"\n",
    "with json_file_1.open(\"r\") as f:\n",
    "    data_1 = json.load(f)\n",
    "with json_file_2.open(\"r\") as f:\n",
    "    data_2 = json.load(f)\n",
    "data = data_1 + data_2\n",
    "source_xlxs = BASE_DIR / \"eval_ehr_100_samples.xlsx\"\n",
    "df = pd.read_excel(source_xlxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was patient 12724975 diagnosed with hypoxemia until 1 year ago and did a chest x-ray reveal any tubes/lines in the abdomen during the same period?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[60][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was patient 12724975 diagnosed with hypoxemia until 1 year ago and did a chest x-ray reveal any tubes/lines in the abdomen during the same period?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'Summary': 'Patient 12724975 was diagnosed with hypoxemia until about two years ago and no tubes/lines were detected in the abdomen during chest x-rays in the last year.', 'details': 'The patient had a diagnosis of hypoxemia recorded on 2103-12-27. Chest x-ray analysis from the last year (2104-12-31 to 2105-12-31) revealed no tubes or lines in the abdomen.', 'source': 'Diagnosis records and chest x-ray image analysis.', 'inference': 'no', 'extra explanation': 'The diagnosis occurred two years ago, not within the last year. No tubes or lines were observed in the x-rays.'}]\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[60][\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Plans (updated with SQL)', 'prediction', 'question'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_df = pd.DataFrame(data)\n",
    "# rename the columns\n",
    "json_df = json_df.rename(columns={\"plans\": \"Plans (updated with SQL)\", \"predictions\": \"prediction\"})\n",
    "json_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in json_df.iterrows():\n",
    "    question = row[\"question\"]\n",
    "\n",
    "    df.loc[df['question'] == question, 'Plans (updated with SQL)'] = str(row['Plans (updated with SQL)'])\n",
    "    df.loc[df['question'] == question, 'prediction'] = str(row['prediction'])\n",
    "\n",
    "output_xlsx = BASE_DIR / \"eval_ehr_100_samples_updated.xlsx\"\n",
    "df.to_excel(output_xlsx, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df[\"id\"] = 0\n",
    "for index, row in json_df.iterrows():\n",
    "    question = row[\"question\"]\n",
    "    question_id = df[df[\"question\"] == question][\"id\"].values[0]\n",
    "    json_df.loc[index, \"id\"] = question_id\n",
    "json_df[\"id\"] = json_df[\"id\"].astype(int)\n",
    "\n",
    "json_data = json_df.to_dict(orient=\"records\")\n",
    "\n",
    "json_folder = EHRXQA_CFG.output_dir / \"xmode-vqa-gpt_4o-english-13-details-reduced-tagged\"\n",
    "json_folder.mkdir(parents=True, exist_ok=True)\n",
    "for d in json_data:\n",
    "    i = d[\"id\"]\n",
    "    with (json_folder / f\"{i}.json\").open(\"w\") as f:\n",
    "        json.dump(d, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[0][\"question_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00<00:00, 269.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "data_path = EHRXQA_CFG.dataset_file\n",
    "eval_folder = EHRXQA_CFG.output_dir / f\"{BASE_NAME}-langsmith-extract-details-reduced\"\n",
    "assert eval_folder.exists(), f\"{eval_folder} does not exist\"\n",
    "output_folder = EHRXQA_CFG.output_dir / f\"{BASE_NAME}-langsmith-extract-details-reduced-tagged\"\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with data_path.open(\"r\") as f:\n",
    "    data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "for eval_file in tqdm(list(eval_folder.glob(\"*.json\"))):\n",
    "    with eval_file.open(\"r\") as f:\n",
    "        eval_data = json.load(f)\n",
    "    question = eval_data[\"question\"]\n",
    "    question_id = df[df[\"question\"] == question][\"id\"].values[0]\n",
    "    eval_data[\"id\"] = int(question_id)\n",
    "    with (output_folder / f\"{question_id}.json\").open(\"w\") as f:\n",
    "        json.dump(eval_data, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3lx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
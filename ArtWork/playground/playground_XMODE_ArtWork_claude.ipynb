{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "bootstrap"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().resolve()\n",
    "while repo_root != repo_root.parent and not ((repo_root / 'src').exists() and (repo_root / 'ArtWork').exists()):\n",
    "    repo_root = repo_root.parent\n",
    "\n",
    "if not (repo_root / 'src').exists():\n",
    "    raise RuntimeError('Could not locate repository root containing src/')\n",
    "\n",
    "artwork_dir = repo_root / 'ArtWork'\n",
    "\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "if str(artwork_dir) not in sys.path:\n",
    "    sys.path.insert(1, str(artwork_dir))\n",
    "\n",
    "sys.modules['tools'] = importlib.import_module('ArtWork.tools')\n",
    "sys.modules['tools.backend'] = importlib.import_module('ArtWork.tools.backend')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude Playground\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U --quiet langchain-openai langchain-anthropic langsmith langgraph langchain numexpr langchainhub sqlalchemy langchain-community matplotlib torch==2.0.0 torchvision==0.15.1 transformers sentence-transformers[train]==3.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from src.settings import get_settings\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "settings = get_settings()\n",
    "BASE_DIR = settings.base_dir\n",
    "ARTWORK_CFG = settings.artwork\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "# _set_if_undefined(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"XMODE-artWork\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(BASE_DIR))\n",
    "sys.path.append(str(BASE_DIR / 'src'))\n",
    "sys.path.append(str(BASE_DIR / 'tools'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bleon/git/XMODE/ArtWork'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "from langchain import hub\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.tools import BaseTool\n",
    "from src.llm_factory import build_chat_model, build_structured_runnable\n",
    "from src.output_parser import M3LXPlanParser, Task\n",
    "from src.utils import _get_db_schema\n",
    "from tools.backend.image_qa import VisualQA\n",
    "from tools.SQL import get_text2SQL_tools\n",
    "from tools.visual_qa import get_image_analysis_tools\n",
    "from tools.plot import get_plotting_tools\n",
    "from tools.data import get_data_preparation_tools\n",
    "provider = \"anthropic\"\n",
    "model = settings.models.anthropic_model\n",
    "db_path = ARTWORK_CFG.db_path\n",
    "temperature = settings.models.default_temperature\n",
    "LOG_PATH = ARTWORK_CFG.log_dir\n",
    "## Tools\n",
    "vqa_model = VisualQA()\n",
    "translate = get_text2SQL_tools(build_chat_model(provider=provider, model=model, temperature=temperature), str(db_path))\n",
    "image_analysis = get_image_analysis_tools(vqa_model)\n",
    "data_preparation = get_data_preparation_tools(build_chat_model(provider=provider, model=model, temperature=temperature), log_path=str(LOG_PATH))\n",
    "plotting = get_plotting_tools(build_chat_model(provider=provider, model=model, temperature=temperature), log_path=str(LOG_PATH))\n",
    "tools = [translate, image_analysis, data_preparation, plotting]\n",
    " # For each image analysis task, generate three distinct questions that each convey the same idea in different wording.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "(\"system\",'''Given a user question, a database schema and tools descriptions, analyze the question to identify and break it down into relevant sub-questions. \n",
    "    Determine which tools (e.g., text2SQL, image_analysis, data_preparation, plotting) are appropriate for answering each sub-question based on the available database information and tools.\n",
    "    Decompose the user question into sub_questions that capture all elements of the question’s intent. This includes identifying the main objective, relevant sub-questions, necessary background information, assumptions, and any secondary requirements. \n",
    "    Ensure that no part of the original question’s intent is omitted, and create a list of individual steps to answer the question fully and accurately using tools. \n",
    "    You may need to use one tool multiple times to answer to the original question.\n",
    "    First, you should begin by thoroughly analyzing the user's main question. It’s important to understand the key components and objectives within the query.\n",
    "    Next, you must review the provided database schema. This involves examining the tables, fields, and relationships within the database to identify which parts of the schema are relevant to the user’s question, and create a text2SQL sub-question.\n",
    "    For each sub-question, provide all the required information that may required in other tasks. In order to find this information look at the user question and the database inforamtion.\n",
    "    Ensure you include all necessary information, including columns used for filtering in the retrieve part of the database related task (i.e. Text2SQL), especially when the user question involves plotting or data exploration.\n",
    "    In sub_question related to text2SQL include all requested information to be retrieved at once.\n",
    "    In cases where the user’s question involves data that is not directly available in the database schema —such as when there is no corresponding table or column for the required information or image analysis— you must consider the need for image analysis using the image_analysis tools. \n",
    "    For instance, if the question involves comparision of image, or asking for specific objects or a object, concepts or a concepts which is not found in the database schema, you must retrieve the `imag_path` and call image analysis task, (e.g, which image depicts <X>).\n",
    "    This ensures we can address parts of the question that rely on visual data.\n",
    "    Try to include data_preparation to provide response to user questions in proper way.\n",
    "    In case the question asked for plotting, you must include first data_preparation and then the data_plotting tools.\n",
    "    With a clear understanding of the question and the database schema, you can now break down the main question into smaller, more manageable sub-questions. \n",
    "    These sub-questions should each target a specific aspect of the main question. \n",
    "    After identifying the sub-questions, you should determine the most appropriate tools to answer each one. Depending on the nature of the sub-questions, we might use a variety of tools.\n",
    "    Each sub-question should be a textual question. Dont generate a code as a sub-question.\n",
    "    In any database retreival task, retieve any other columns that may requir for next tasks, especially when the user question involves plotting or data exploration.\n",
    "    Create a plan to solve it with the utmost parallelizability. \n",
    "    Each plan should comprise an action from the following  {num_tools} types:\n",
    "{tool_descriptions}\n",
    "{num_tools}. \n",
    "join(): Collects and combines results from prior actions.\n",
    "- An LLM agent is called upon invoking join() to either finalize the user query or wait until the plans are executed.\n",
    "- join should always be the last action in the plan, and will be called in two scenarios:\n",
    "(a) if the answer can be determined by gathering the outputs from tasks to generate the final response.\n",
    "(b) if the answer cannot be determined in the planning phase before you execute the plans. Guidelines:\n",
    "- Each action described above contains input/output types and description.\n",
    "- You must strictly adhere to the input and output types for each action.\n",
    "- The action descriptions contain the guidelines. You MUST strictly follow those guidelines when you use the actions.\n",
    "- Each action in the plan should strictly be one of the above types. Follow the Python conventions for each action.\n",
    "- Each action MUST have a unique ID, which is strictly increasing.\n",
    "- Inputs for actions can either be constants or outputs from preceding actions. In the latter case, use the format $id to denote the ID of the previous action whose output will be the input.\n",
    "- If there is an input from from preceding actions, always point its id as `$id` in the context of the action/\n",
    "- Always call join as the last action in the plan. Say '<END_OF_PLAN>' after you call join\n",
    "- Ensure the plan maximizes parallelizability.\n",
    "- Only use the provided action types. If a query cannot be addressed using these, invoke the join action for the next steps.\n",
    "- Never introduce new actions other than the ones provided.'''),\n",
    "    (\"user\", '{messages}'),\n",
    "    (\"assistant\", 'Remember, ONLY respond with the task list in the correct format! E.g.:\\nidx. tool(arg_name=args)'),\n",
    "]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_planner(\n",
    "    llm: BaseChatModel, tools: Sequence[BaseTool], base_prompt: ChatPromptTemplate, database_schema:str=None\n",
    "):\n",
    "    tool_descriptions = \"\\n\".join(\n",
    "        f\"{i+1}. {tool.description}\\n\"\n",
    "        for i, tool in enumerate(\n",
    "            tools\n",
    "        )  # +1 to offset the 0 starting index, we want it count normally from 1.\n",
    "    )\n",
    "    planner_prompt = base_prompt.partial(\n",
    "        replan=\"\",\n",
    "\n",
    "        num_tools=len(tools)\n",
    "        + 1,  # Add one because we're adding the join() tool at the end.\n",
    "        tool_descriptions = tool_descriptions,\n",
    "        #database_schema=database_schema,\n",
    "    )\n",
    "    replanner_prompt = base_prompt.partial(\n",
    "        replan=' - You are given \"Previous Plan\" which is the plan that the previous agent created along with the execution results '\n",
    "        \"(given as Observation) of each plan and a general thought (given as Thought) about the executed results.\"\n",
    "        'You MUST use these information to create the next plan under \"Current Plan\".\\n'\n",
    "        ' - When starting the Current Plan, you should start with \"Thought\" that outlines the strategy for the next plan.\\n'\n",
    "        \" - In the Current Plan, you should NEVER repeat the actions that are already executed in the Previous Plan.\\n\"\n",
    "        \" - You must continue the task index from the end of the previous one. Do not repeat task indices.\",\n",
    "        num_tools = len(tools) + 1,\n",
    "        tool_descriptions=tool_descriptions,\n",
    "        #database_schema=database_schema,\n",
    "    )\n",
    "\n",
    "    def should_replan(state: list):\n",
    "        # Context is passed as a system message\n",
    "        return isinstance(state[-1], SystemMessage)\n",
    "\n",
    "    def wrap_messages(state: list):\n",
    "        # print(\"wrap_messages state:\", state)\n",
    "        return {\"messages\": state}\n",
    "\n",
    "    def wrap_and_get_last_index(state: list):\n",
    "        next_task = 0\n",
    "        for message in state[::-1]:\n",
    "            if isinstance(message, FunctionMessage):\n",
    "                next_task = message.additional_kwargs[\"idx\"] + 1\n",
    "                break\n",
    "        state[-1].content = state[-1].content + f\" - Begin counting at : {next_task}\"\n",
    "        return {\"messages\": state}\n",
    "\n",
    "    return (\n",
    "                RunnableBranch(\n",
    "                    (should_replan, wrap_and_get_last_index | replanner_prompt),\n",
    "                    wrap_messages | planner_prompt,\n",
    "                )\n",
    "                | llm\n",
    "                | M3LXPlanParser(tools=tools)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = build_chat_model(provider=provider, model=model, temperature=temperature)\n",
    "planner = create_planner(llm, tools, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"enumerate all detected abnormalities, given the study 57883509.\"\n",
    "example_question=\"Create a graph of all pictures depicting religious themes\"\n",
    "# id= 2000\n",
    "database_schema =_get_db_schema(db_path)\n",
    "inputs = {\"question\": example_question, \"database_schema\":database_schema}\n",
    "# config = {\"configurable\": {\"thread_id\": \"xmode-2000\"}}\n",
    "inputs=[HumanMessage(content=[inputs])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:54:23,033 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='text2SQL' description=\"text2SQL(problem: str, context: Optional[Union[str,list[str]]])-->str\\nThe input for this tools should be `problem` as a textual question\\n - You can optionally provide a list of strings as `context` to help the agent solve the problem. If there are multiple contexts you need to answer the question, you can provide them as a list of strings.\\nIn the 'context' you could add any other information that you think is required to generate te SQL code. It can be the information from previous taks.\\nThis tools is able to translate the question to the SQL code considering the database information.\\nThe SQL code can be executed using sqlite3 library.\\nUse the output of running generated SQL code to answer the question.\" args_schema=<class 'langchain_core.utils.pydantic.text2SQL'> func=<function get_text2SQL_tools.<locals>.text2SQL at 0x7fa68adffe20> {'problem': 'How many paintings have Jesus in them?', 'context': ['paintings table contains religious art images']}\n",
      "---\n",
      "name='data_preparation' description='data_preparation (question:str, context: Union[str, List[str],dict])-> str\\n This tools is a data preparation task. For given data and question, it porcess the data and prepare the proper data structure for a request. \\n - Minimize the number of `data_preparation` actions as much as possible. if you want this tools does its job properly, you should include all required information from the user query in previous tasks.' args_schema=<class 'langchain_core.utils.pydantic.data_preparation'> func=<function get_data_preparation_tools.<locals>.data_preparation at 0x7fa68adf5a80> {'question': 'Prepare data for plotting number of Jesus paintings', 'context': '$1'}\n",
      "---\n",
      "name='data_plotting' description='data_plotting (question:str, context: Union[str, List[str],dict])-> str\\n This tools is a data plotting task. For given data and a question, it analysis the data and plot a proper chart to answer a user query. \\n - Minimize the number of `data_plotting` actions as much as possible. if you want this tools does its job properly, you should include all required information from the user query in previous tasks.' args_schema=<class 'langchain_core.utils.pydantic.data_plotting'> func=<function get_plotting_tools.<locals>.data_plotting at 0x7fa68adf4fe0> {'question': 'Plot number of paintings with Jesus', 'context': '$2'}\n",
      "---\n",
      "join ()\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for task in planner.stream(inputs):\n",
    "    print(task[\"tool\"], task[\"args\"])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Fetching Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from typing import Any, Dict, Iterable, List, Union\n",
    "\n",
    "from langchain_core.runnables import (\n",
    "    chain as as_runnable,\n",
    ")\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "def _get_observations(messages: List[BaseMessage]) -> Dict[int, Any]:\n",
    "    # Get all previous tool responses\n",
    "    results = {}\n",
    "    for message in messages[::-1]:\n",
    "        if isinstance(message, FunctionMessage):\n",
    "            results[int(message.additional_kwargs[\"idx\"])] = message.content\n",
    "    return results\n",
    "\n",
    "\n",
    "class SchedulerInput(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    tasks: Iterable[Task]\n",
    "\n",
    "\n",
    "def _execute_task(task, observations, config):\n",
    "    tool_to_use = task[\"tool\"]\n",
    "    if isinstance(tool_to_use, str):\n",
    "        return tool_to_use\n",
    "    args = task[\"args\"]\n",
    "    try:\n",
    "        if isinstance(args, str):\n",
    "            resolved_args = _resolve_arg(args, observations)\n",
    "        elif isinstance(args, dict):\n",
    "            resolved_args = {\n",
    "                key: _resolve_arg(val, observations) for key, val in args.items()\n",
    "            }\n",
    "        else:\n",
    "            # This will likely fail\n",
    "            resolved_args = args\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"ERROR(Failed to call {tool_to_use.name} with args {args}.)\"\n",
    "            f\" Args could not be resolved. Error: {repr(e)}\"\n",
    "        )\n",
    "    try:\n",
    "        return tool_to_use.invoke(resolved_args, config)\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"ERROR(Failed to call {tool_to_use.name} with args {args}.\"\n",
    "            + f\" Args resolved to {resolved_args}. Error: {repr(e)})\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _resolve_arg(arg: Union[str, Any], observations: Dict[int, Any]):\n",
    "    # $1 or ${1} -> 1\n",
    "    ID_PATTERN = r\"\\$\\{?(\\d+)\\}?\"\n",
    "\n",
    "    def replace_match(match):\n",
    "        # If the string is ${123}, match.group(0) is ${123}, and match.group(1) is 123.\n",
    "\n",
    "        # Return the match group, in this case the index, from the string. This is the index\n",
    "        # number we get back.\n",
    "        idx = int(match.group(1))\n",
    "        return str(observations.get(idx, match.group(0)))\n",
    "\n",
    "    # For dependencies on other tasks\n",
    "    if isinstance(arg, str):\n",
    "        return re.sub(ID_PATTERN, replace_match, arg)\n",
    "    elif isinstance(arg, list):\n",
    "        return [_resolve_arg(a, observations) for a in arg]\n",
    "    else:\n",
    "        return str(arg)\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def schedule_task(task_inputs, config):\n",
    "    task: Task = task_inputs[\"task\"]\n",
    "    observations: Dict[int, Any] = task_inputs[\"observations\"]\n",
    "    try:\n",
    "        observation = _execute_task(task, observations, config)\n",
    "    except Exception:\n",
    "        import traceback\n",
    "\n",
    "        observation = traceback.format_exception()  # repr(e) +\n",
    "    observations[task[\"idx\"]] = observation\n",
    "\n",
    "\n",
    "def schedule_pending_task(\n",
    "    task: Task, observations: Dict[int, Any], retry_after: float = 0.2\n",
    "):\n",
    "    while True:\n",
    "        deps = task[\"dependencies\"]\n",
    "        if deps and (any([dep not in observations for dep in deps])):\n",
    "            # Dependencies not yet satisfied\n",
    "            time.sleep(retry_after)\n",
    "            continue\n",
    "        schedule_task.invoke({\"task\": task, \"observations\": observations})\n",
    "        break\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def schedule_tasks(scheduler_input: SchedulerInput) -> List[FunctionMessage]:\n",
    "    \"\"\"Group the tasks into a DAG schedule.\"\"\"\n",
    "    # For streaming, we are making a few simplifying assumption:\n",
    "    # 1. The LLM does not create cyclic dependencies\n",
    "    # 2. That the LLM will not generate tasks with future deps\n",
    "    # If this ceases to be a good assumption, you can either\n",
    "    # adjust to do a proper topological sort (not-stream)\n",
    "    # or use a more complicated data structure\n",
    "    tasks = scheduler_input[\"tasks\"]\n",
    "    args_for_tasks = {}\n",
    "    messages = scheduler_input[\"messages\"]\n",
    "    # If we are re-planning, we may have calls that depend on previous\n",
    "    # plans. Start with those.\n",
    "    observations = _get_observations(messages)\n",
    "    task_names = {}\n",
    "    originals = set(observations)\n",
    "    # ^^ We assume each task inserts a different key above to\n",
    "    # avoid race conditions...\n",
    "    futures = []\n",
    "    retry_after = 0.25  # Retry every quarter second\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for task in tasks:\n",
    "            deps = task[\"dependencies\"]\n",
    "            task_names[task[\"idx\"]] = (\n",
    "                task[\"tool\"] if isinstance(task[\"tool\"], str) else task[\"tool\"].name\n",
    "            )\n",
    "            args_for_tasks[task[\"idx\"]] = task[\"args\"]\n",
    "            if (\n",
    "                # Depends on other tasks\n",
    "                deps\n",
    "                and (any([dep not in observations for dep in deps]))\n",
    "            ):\n",
    "                futures.append(\n",
    "                    executor.submit(\n",
    "                        schedule_pending_task, task, observations, retry_after\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # No deps or all deps satisfied\n",
    "                # can schedule now\n",
    "                schedule_task.invoke(dict(task=task, observations=observations))\n",
    "                # futures.append(executor.submit(schedule_task.invoke dict(task=task, observations=observations)))\n",
    "\n",
    "        # All tasks have been submitted or enqueued\n",
    "        # Wait for them to complete\n",
    "        wait(futures)\n",
    "    # Convert observations to new tool messages to add to the state\n",
    "    new_observations = {\n",
    "        k: (task_names[k], args_for_tasks[k], observations[k])\n",
    "        for k in sorted(observations.keys() - originals)\n",
    "    }\n",
    "    tool_messages = [\n",
    "        FunctionMessage(\n",
    "            name=name, content=str(obs), additional_kwargs={\"idx\": k, \"args\": task_args}\n",
    "        )\n",
    "        for k, (name, task_args, obs) in new_observations.items()\n",
    "    ]\n",
    "    return tool_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def plan_and_schedule(messages: List[BaseMessage], config):\n",
    "    tasks = planner.stream(messages, config)\n",
    "    # Begin executing the planner immediately\n",
    "    try:\n",
    "        tasks = itertools.chain([next(tasks)], tasks)\n",
    "    except StopIteration:\n",
    "        # Handle the case where tasks is empty.\n",
    "        tasks = iter([])\n",
    "    scheduled_tasks = schedule_tasks.invoke(\n",
    "        {\n",
    "            \"messages\": messages,\n",
    "            \"tasks\": tasks,\n",
    "        },\n",
    "        config,\n",
    "    )\n",
    "    return scheduled_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:54:29,149 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-11-07 10:54:32,687 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-first: {'status': 'success', 'data': [{'paintings_with_jesus': 7}]} <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:54:38,671 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-first: {\n",
      "  \"category\": \"Religious Art\",\n",
      "  \"subject\": \"Jesus Paintings\", \n",
      "  \"count\": 7\n",
      "} <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:54:43,688 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[FunctionMessage(content=\"{'status': 'success', 'data': [{'paintings_with_jesus': 7}]}\", additional_kwargs={'idx': 1, 'args': {'problem': 'How many paintings have Jesus in them?', 'context': ['paintings table contains religious art images']}}, response_metadata={}, name='text2SQL'),\n",
       " FunctionMessage(content='{\\n  \"category\": \"Religious Art\",\\n  \"subject\": \"Jesus Paintings\", \\n  \"count\": 7\\n}', additional_kwargs={'idx': 2, 'args': {'question': 'Prepare data for plotting number of Jesus paintings', 'context': '$1'}}, response_metadata={}, name='data_preparation'),\n",
       " FunctionMessage(content='import matplotlib.pyplot as plt\\n\\n# Data from the provided JSON\\ncategory = \"Religious Art\"\\nsubject = \"Jesus Paintings\"\\ncount = 7\\n\\n# Create a bar plot\\nplt.figure(figsize=(8, 5))\\nplt.bar([subject], [count], color=\\'skyblue\\', edgecolor=\\'navy\\')\\nplt.title(f\\'Number of Paintings in {category}\\', fontsize=14)\\nplt.ylabel(\\'Number of Paintings\\', fontsize=12)\\nplt.xlabel(\\'Subject\\', fontsize=12)\\n\\n# Add the count on top of the bar\\nplt.text(0, count, str(count), ha=\\'center\\', va=\\'bottom\\', fontsize=12)\\n\\n# Adjust layout and save the plot\\nplt.tight_layout()\\nplt.savefig(\\'/home/bleon/git/XMODE/ArtWork/experiments/log/jesus_paintings.png\\')\\nplt.close()', additional_kwargs={'idx': 3, 'args': {'question': 'Plot number of paintings with Jesus', 'context': '$2'}}, response_metadata={}, name='data_plotting'),\n",
       " FunctionMessage(content='join', additional_kwargs={'idx': 4, 'args': ()}, response_metadata={}, name='join')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_messages = plan_and_schedule.invoke(inputs)\n",
    "tool_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Sequence\n",
    "from typing import Any, Callable, Dict, Literal, Optional, Sequence, Type, Union, List\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from typing import Any, Dict, Iterable, List, Union\n",
    "from langchain_core.runnables import (\n",
    "    chain as as_runnable,\n",
    ")\n",
    "class FinalResponse(BaseModel):\n",
    "    \"\"\"The final response/answer.\"\"\"\n",
    "    response: Union[str,Dict]\n",
    "class Replan(BaseModel):\n",
    "    feedback: str = Field(\n",
    "        description=\"Analysis of the previous attempts and recommendations on what needs to be fixed.\"\n",
    "    )\n",
    "class JoinOutputs(BaseModel):\n",
    "    \"\"\"Decide whether to replan or whether you can return the final response.\"\"\"\n",
    "    thought: str = Field(\n",
    "        description=\"The chain of thought reasoning for the selected action\"\n",
    "    )\n",
    "    action: Union[FinalResponse, Replan]\n",
    "    \n",
    "joiner_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"system\",'''Solve a question answering task. Here are some guidelines:\n",
    "    - In the Assistant Scratchpad, you will be given results of a plan you have executed to answer the user's question.\n",
    "    - Thought needs to reason about the question based on the Observations in 1-2 sentences.\n",
    "    - Ignore irrelevant action results.\n",
    "    - If the required information is present, give a concise but complete and helpful answer to the user's question.\n",
    "    - If you are unable to give a satisfactory finishing answer, replan to get the required information. Respond in the following format:\n",
    "    Thought: <reason about the task results and whether you have sufficient information to answer the question>\n",
    "    Action: <action to take>\n",
    "    - If an error occurs during previous actions, replan and take corrective measures to obtain the required information.\n",
    "    - Ensure that you consider errors in all the previous steps, and tries to replan accordingly.\n",
    "    - Ensure the final answer is provided in a structured format as JSON as follows:\n",
    "        {{'Summary': <concise summary of the answer>,\n",
    "         'details': <detailed explanation and supporting information>,\n",
    "         'source': <source of the information or how it was obtained>,\n",
    "         'inference':<your final inference as YES, No, or list of requested information without any extra information which you can take from the `labels` as given below>,\n",
    "         'extra explanation':<put here the extra information that you dont provide in inference >,\n",
    "         }}\n",
    "         In the `inferencer` do not provide additinal explanation or description. Put them in `extra explanation`.\n",
    "       \n",
    "    Available actions:\n",
    "    (1) Finish(the final answer to return to the user): returns the answer and finishes the task.\n",
    "    (2) Replan(the reasoning and other information that will help you plan again. Can be a line of any length): instructs why we must replan\n",
    "    ''' ),\n",
    "        (\"user\", '{messages}'),\n",
    "        ]\n",
    "    ).partial(\n",
    "        examples=\"\"\n",
    "    )  \n",
    "runnable = build_structured_runnable(llm, joiner_prompt, JoinOutputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_joiner_output(decision: JoinOutputs) -> List[BaseMessage]:\n",
    "    response = [AIMessage(content=f\"Thought: {decision.thought}\")]\n",
    "    if isinstance(decision.action, Replan):\n",
    "        return response + [\n",
    "            SystemMessage(\n",
    "                content=f\"Context from last attempt: {decision.action.feedback}\"\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        return response + [AIMessage(content=str(decision.action.response))]\n",
    "\n",
    "\n",
    "def select_recent_messages(messages: list) -> dict:\n",
    "    selected = []\n",
    "    for msg in messages[::-1]:\n",
    "        selected.append(msg)\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            break\n",
    "    return {\"messages\": selected[::-1]}\n",
    "\n",
    "\n",
    "joiner = select_recent_messages | runnable | _parse_joiner_output\n",
    "\n",
    "#input_messages = inputs + tool_messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Plan and schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:54:45,062 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-11-07 10:54:49,934 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-first: {'status': 'success', 'data': [{'paintings_with_jesus': 7}]} <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:54:58,331 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-first: {\n",
      "  \"artwork_category\": \"Jesus Paintings\",\n",
      "  \"total_paintings\": 7,\n",
      "  \"visualization_metadata\": {\n",
      "    \"x_axis_label\": \"Number of Paintings\", \n",
      "    \"y_axis_label\": \"Jesus Artwork Count\",\n",
      "    \"title\": \"Count of Jesus Paintings\"\n",
      "  }\n",
      "} <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:55:03,144 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-11-07 10:55:08,446 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Thought: The query asks about the number of paintings featuring Jesus. From the previous function calls, we have determined that there are 7 paintings with Jesus in them, and a plot has been generated to visualize this information.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='{\\'Summary\\': \\'7 paintings featuring Jesus were found in the database\\', \\'details\\': \\'A total of 7 paintings depicting Jesus were identified from the religious art collection\\', \\'source\\': \\'SQL query on the paintings table\\', \\'inference\\': 7, \\'extra explanation\\': \"A bar plot visualizing the count of Jesus paintings has been created and saved at \\'/home/bleon/git/XMODE/ArtWork/experiments/log/jesus_paintings_count.png\\'\"}', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_messages = plan_and_schedule.invoke(inputs)\n",
    "\n",
    "input_messages = inputs + tool_messages\n",
    "\n",
    "joiner.invoke(input_messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compse uning LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4421/1695062163.py:5: LangGraphDeprecatedSinceV10: MessageGraph is deprecated in LangGraph v1.0.0, to be removed in v2.0.0. Please use StateGraph with a `messages` key instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  graph_builder = MessageGraph()\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langgraph.graph import END, MessageGraph, START\n",
    "\n",
    "graph_builder = MessageGraph()\n",
    "\n",
    "# 1.  Define vertices\n",
    "# We defined plan_and_schedule above already\n",
    "# Assign each node to a state variable to update\n",
    "graph_builder.add_node(\"plan_and_schedule\", plan_and_schedule)\n",
    "graph_builder.add_node(\"join\", joiner)\n",
    "\n",
    "\n",
    "## Define edges\n",
    "graph_builder.add_edge(\"plan_and_schedule\", \"join\")\n",
    "\n",
    "### This condition determines looping logic\n",
    "\n",
    "\n",
    "def should_continue(state: List[BaseMessage]):\n",
    "    if isinstance(state[-1], AIMessage):\n",
    "        return END\n",
    "    return \"plan_and_schedule\"\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "        \"join\",\n",
    "        # Next, we pass in the function that will determine which node is called next.\n",
    "        should_continue,\n",
    "        #{\"plan_and_schedule\": \"plan_and_schedule\", \"__end__\": \"__end__\"},\n",
    "    )\n",
    "graph_builder.add_edge(START, \"plan_and_schedule\")\n",
    "chain = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:55:09,660 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-11-07 10:55:13,831 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-first: {'status': 'success', 'data': [{'jesus_paintings_count': 56}]} <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:55:19,044 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-first: {\n",
      "  \"category\": \"Religious Art\",\n",
      "  \"subject\": \"Jesus Paintings\",\n",
      "  \"count\": 56\n",
      "} <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:55:23,624 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-11-07 10:55:28,538 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=[{'question': 'Wie viele Bilder haben Jesus drauf plotte die antwort.', 'database_schema': '\\nCREATE TABLE paintings (\\n\\ttitle TEXT, \\n\\tinception DATETIME, \\n\\tmovement TEXT, \\n\\tgenre TEXT, \\n\\timage_url TEXT, \\n\\timg_path TEXT\\n)\\n\\n/*\\n5 rows from paintings table:\\ntitle\\tinception\\tmovement\\tgenre\\timage_url\\timg_path\\nPredella of the Barbadori altarpiece\\t1438-01-01 00:00:00\\tRenaissance\\treligious art\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Predella%20Pala%20Barbadori-%20Uffizi.JPG\\timages/img_0.jpg\\nJudith\\t1525-01-01 00:00:00\\tRenaissance\\treligious art\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Palma%20il%20Vecchio%20-%20Judith%20-%20WGA16936.\\timages/img_1.jpg\\nJudith\\t1528-01-01 00:00:00\\tRenaissance\\treligious art\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Palma%20il%20Vecchio%20-%20Judith%20-%20WGA16936.\\timages/img_2.jpg\\nDie durch Engel bekrönte Muttergottes mit Kind im Kreise der 14 Schutzheiligen des Hauses Zimmern\\t1536-01-01 00:00:00\\tRenaissance\\treligious art\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Meister%20von%20Me%C3%9Fkirch-Wildensteiner%20Alt\\timages/img_3.jpg\\nDer kniende Stifter Graf Gottfried Werner von Zimmern – Christus am Ölberg\\t1536-01-01 00:00:00\\tRenaissance\\tportrait\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Meister%20von%20Me%C3%9Fkirch-Wildensteiner%20Alt\\timages/img_4.jpg\\n*/'}] additional_kwargs={} response_metadata={} id='c1a11401-d5c1-43ae-9a37-08d0fbc82cdf'\n",
      "---\n",
      "content=\"{'status': 'success', 'data': [{'jesus_paintings_count': 56}]}\" additional_kwargs={'idx': 1, 'args': {'problem': 'How many paintings depict Jesus?', 'context': ['Find paintings with Jesus in the title or genre']}} response_metadata={} name='text2SQL' id='525a3b25-8aa6-4b60-88fd-9c898b16c42c'\n",
      "---\n",
      "content='{\\n  \"category\": \"Religious Art\",\\n  \"subject\": \"Jesus Paintings\",\\n  \"count\": 56\\n}' additional_kwargs={'idx': 2, 'args': {'question': 'Prepare data for plotting', 'context': '$1'}} response_metadata={} name='data_preparation' id='c0ebc254-b305-45cb-97ac-8cac19dc8abe'\n",
      "---\n",
      "content='import matplotlib.pyplot as plt\\n\\n# Data from the provided JSON\\ncategory = \"Religious Art\"\\nsubject = \"Jesus Paintings\"\\ncount = 56\\n\\n# Create a bar plot\\nplt.figure(figsize=(8, 5))\\nplt.bar([subject], [count], color=\\'skyblue\\', edgecolor=\\'navy\\')\\nplt.title(f\\'Number of {subject} in {category}\\')\\nplt.ylabel(\\'Number of Paintings\\')\\nplt.xlabel(\\'Subject\\')\\n\\n# Add the count on top of the bar\\nplt.text(0, count, str(count), ha=\\'center\\', va=\\'bottom\\')\\n\\n# Save the plot\\nplt.tight_layout()\\nplt.savefig(\\'/home/bleon/git/XMODE/ArtWork/experiments/log/jesus_paintings.png\\')\\nplt.close()' additional_kwargs={'idx': 3, 'args': {'question': 'Plot number of Jesus paintings', 'context': '$2'}} response_metadata={} name='data_plotting' id='23fe9e53-5139-4a30-ba49-ee47196468e0'\n",
      "---\n",
      "content='join' additional_kwargs={'idx': 4, 'args': ()} response_metadata={} name='join' id='1700b7c6-7316-45a8-8187-9d81b83fcb3c'\n",
      "---\n",
      "content='Thought: The query asks about the number of paintings depicting Jesus. The data analysis and plotting have been completed, showing 56 paintings of Jesus in the religious art category.' additional_kwargs={} response_metadata={} id='50d4d6f3-93fa-4573-9881-7e4cd1195714'\n",
      "---\n",
      "content='{\\'Summary\\': \\'56 paintings depicting Jesus were found in the database\\', \\'details\\': \\'The paintings are categorized under Religious Art, with a total count of 56 paintings featuring Jesus as the subject\\', \\'source\\': \\'SQL database query and data analysis\\', \\'inference\\': 56, \\'extra explanation\\': \"A bar plot visualizing the number of Jesus paintings has been generated and saved at \\'/home/bleon/git/XMODE/ArtWork/experiments/log/jesus_paintings.png\\'\"}' additional_kwargs={} response_metadata={} id='4c7213fc-bd0f-451a-9ce2-f39813461d70'\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for step in chain.invoke(inputs):\n",
    "    print(step)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:55:29,767 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-11-07 10:55:35,551 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-first: {'status': 'success', 'data': [{'jesus_paintings_count': 8}]} <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:55:39,945 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-first: {\n",
      "  \"jesus_images\": {\n",
      "    \"total_count\": 8,\n",
      "    \"visualization_label\": \"Number of Jesus Images\"\n",
      "  }\n",
      "} <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 10:55:45,047 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-11-07 10:55:49,738 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=[{'question': 'Wie viele Bilder haben Jesus drauf plotte die antwort.', 'database_schema': '\\nCREATE TABLE paintings (\\n\\ttitle TEXT, \\n\\tinception DATETIME, \\n\\tmovement TEXT, \\n\\tgenre TEXT, \\n\\timage_url TEXT, \\n\\timg_path TEXT\\n)\\n\\n/*\\n5 rows from paintings table:\\ntitle\\tinception\\tmovement\\tgenre\\timage_url\\timg_path\\nPredella of the Barbadori altarpiece\\t1438-01-01 00:00:00\\tRenaissance\\treligious art\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Predella%20Pala%20Barbadori-%20Uffizi.JPG\\timages/img_0.jpg\\nJudith\\t1525-01-01 00:00:00\\tRenaissance\\treligious art\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Palma%20il%20Vecchio%20-%20Judith%20-%20WGA16936.\\timages/img_1.jpg\\nJudith\\t1528-01-01 00:00:00\\tRenaissance\\treligious art\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Palma%20il%20Vecchio%20-%20Judith%20-%20WGA16936.\\timages/img_2.jpg\\nDie durch Engel bekrönte Muttergottes mit Kind im Kreise der 14 Schutzheiligen des Hauses Zimmern\\t1536-01-01 00:00:00\\tRenaissance\\treligious art\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Meister%20von%20Me%C3%9Fkirch-Wildensteiner%20Alt\\timages/img_3.jpg\\nDer kniende Stifter Graf Gottfried Werner von Zimmern – Christus am Ölberg\\t1536-01-01 00:00:00\\tRenaissance\\tportrait\\thttp://commons.wikimedia.org/wiki/Special:FilePath/Meister%20von%20Me%C3%9Fkirch-Wildensteiner%20Alt\\timages/img_4.jpg\\n*/'}] additional_kwargs={} response_metadata={} id='c1a11401-d5c1-43ae-9a37-08d0fbc82cdf'\n",
      "---\n",
      "content=\"{'status': 'success', 'data': [{'jesus_paintings_count': 8}]}\" additional_kwargs={'idx': 1, 'args': {'problem': 'How many paintings depict Jesus?', 'context': ['Find paintings with religious themes related to Jesus']}} response_metadata={} name='text2SQL' id='9bfc6c9e-5f0e-466c-9ad8-35abd77e56bf'\n",
      "---\n",
      "content='{\\n  \"jesus_images\": {\\n    \"total_count\": 8,\\n    \"visualization_label\": \"Number of Jesus Images\"\\n  }\\n}' additional_kwargs={'idx': 2, 'args': {'question': 'Prepare data for plotting number of Jesus images', 'context': '$1'}} response_metadata={} name='data_preparation' id='17adce28-71e5-4f36-950c-d6f07129d5c4'\n",
      "---\n",
      "content='import matplotlib.pyplot as plt\\n\\n# Data\\ntotal_count = 8\\nlabel = \"Number of Jesus Images\"\\n\\n# Create the plot\\nplt.figure(figsize=(8, 5))\\nplt.bar([\\'Jesus Images\\'], [total_count], color=\\'skyblue\\')\\nplt.title(label, fontsize=14)\\nplt.ylabel(\\'Count\\', fontsize=12)\\nplt.ylim(0, max(total_count + 2, 10))  # Ensure some headroom above the bar\\n\\n# Add the exact count on top of the bar\\nplt.text(0, total_count, str(total_count), ha=\\'center\\', va=\\'bottom\\', fontsize=12)\\n\\n# Save the plot\\nplt.tight_layout()\\nplt.savefig(\\'/home/bleon/git/XMODE/ArtWork/experiments/log/jesus_images_count.png\\')\\nplt.close()' additional_kwargs={'idx': 3, 'args': {'question': 'Plot number of images with Jesus', 'context': '$2'}} response_metadata={} name='data_plotting' id='6e4f07cb-023e-4026-81f4-2042dfc43355'\n",
      "---\n",
      "content='join' additional_kwargs={'idx': 4, 'args': ()} response_metadata={} name='join' id='57b8ccd5-a640-4807-8129-926876d092b3'\n",
      "---\n",
      "content='Thought: The query asks about the number of images depicting Jesus. From the previous function calls, we have determined that there are 8 paintings featuring Jesus in the database.' additional_kwargs={} response_metadata={} id='c24a24b1-2f04-4cfa-af5b-232ac8cb75a3'\n",
      "---\n",
      "content='{\\'Summary\\': \\'8 paintings depict Jesus in the database\\', \\'details\\': \\'A total of 8 paintings with religious themes related to Jesus were found in the art collection\\', \\'source\\': \\'SQL query on paintings database\\', \\'inference\\': 8, \\'extra explanation\\': \"A bar plot visualizing the count of Jesus images has been generated and saved at \\'/home/bleon/git/XMODE/ArtWork/experiments/log/jesus_images_count.png\\'\"}' additional_kwargs={} response_metadata={} id='cae19509-bbcb-4c3c-9473-7d388881dcda'\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for step in chain.invoke(inputs):\n",
    "    print(step)\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
